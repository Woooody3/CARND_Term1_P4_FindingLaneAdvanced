{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Term 1 Project 4 _FindingLanes\n",
    "\n",
    "To find the lanes from the videos, the following procedure would be proceeded:\n",
    "- define image process functions, \n",
    "- build image process pipeline\n",
    "- run the pipeline on the videos \n",
    "\n",
    "1. Define line and image parameters class \n",
    "- Camera calibration\n",
    "- Image distortion\n",
    "- Image filtering by color & gradient threshold\n",
    "- Image perspective transform to bird-view\n",
    "- Polynomial fit lane line\n",
    "- Visualization on test images for the function testing. \n",
    "- Finally, do visualization on vedios.\n",
    "\n",
    "## 1. Define Functions\n",
    "\n",
    "Classes and functions are built for later use in setting up pipeline.\n",
    "\n",
    "0. Class: Line() and Image_Parameters()\n",
    "1. Camera calibration\n",
    "- Image distortion\n",
    "- Image filtering by color & gradient threshold\n",
    "- Image perspective transform to bird-view\n",
    "- Polynomial fit lane line\n",
    "- Visualization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "''' 1 Define class '''\n",
    "class Line():\n",
    "    def __init__(self):       \n",
    "        self.fit = []     # Polynomial fit parameters [A,B,C] where (A*y**2+B*y+C=x)\n",
    "        # the axis y of pixels which belong to lane \n",
    "        #self.y = []\n",
    "        # the axis x of pixels which belong to lane \n",
    "        #self.x = []\n",
    "        # the linear interpolation y \n",
    "        #self.ploty = []\n",
    "        \n",
    "        self.fitx = []    # The axis x of fitted lane line\n",
    "        self.curverad_m = None # the curvature radius in meter, at the point close to car body\n",
    "\n",
    "class Image_Parameters():\n",
    "    def __init__(self):\n",
    "        self.calibrated = None   # \"ret, mtx, dist, rvecs, tvecs\"\n",
    "        self.M = []              # 3x3 perspective transform matrix\n",
    "        self.Minv = []           # 3x3 reverse perspective transform matrix\n",
    "\n",
    "\n",
    "''' 2 Calibration ''' \n",
    "def calibration(img_path, corner_y, corner_x):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    \n",
    "    # The should-be corner point coordinates\n",
    "    objcorner = np.zeros((corner_y*corner_x,3), np.float32)\n",
    "    objcorner[:, 0:2] = np.mgrid[0:corner_x, 0:corner_y].T.reshape(-1,2)\n",
    "    \n",
    "    # Capture image corner point coordinate\n",
    "    img_cli = glob.glob(img_path)\n",
    "    for idx, fname in enumerate(img_cli):\n",
    "        img = mpimg.imread(fname)  \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (corner_x,corner_y), None)\n",
    "        if ret == True: \n",
    "            objpoints.append(objcorner)\n",
    "            imgpoints.append(corners)\n",
    "    \n",
    "    # Calibration\n",
    "    one_img = mpimg.imread(img_cli[0])\n",
    "    img_size = (one_img.shape[1], one_img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, img_size, None, None)\n",
    "    \n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "''' 3 Undistortion '''\n",
    "# cv2.undistort(image, mtx, dist, None, mtx) \n",
    "\n",
    "''' 4 Image thresholding '''\n",
    "def color_gradient_threshold(img, sx_thresh=(0, 255), sc_thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float32)\n",
    "    H_channel, L_channel, S_channel = hls[:,:,0], hls[:,:,1], hls[:,:,2]\n",
    "\n",
    "    sobel_x = cv2.Sobel(S_channel, cv2.CV_64F, 1, 0)\n",
    "    sbs_sx = np.absolute(sobel_x)\n",
    "    scaled_sx = np.uint8(255*sbs_sx/np.max(sbs_sx))\n",
    "    # gradient thresholding on x axile\n",
    "    sx_binary = np.zeros_like(scaled_sx)\n",
    "    sx_binary[(scaled_sx > sx_thresh[0]) & (scaled_sx <= sx_thresh[1])] = 1\n",
    "    # color thresholding on hls's S color\n",
    "    sc_binary = np.zeros_like(S_channel)\n",
    "    sc_binary[(S_channel > sc_thresh[0]) & (S_channel <= S_channel[1])] = 1\n",
    "    # combined above two threshold into one colored image\n",
    "    combined_binary = np.zeros_like(sx_binary)\n",
    "    combined_binary[(sx_binary==1) | (sc_binary==1)] = 1\n",
    "    \n",
    "    return combined_binary   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Function 2 & 3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' - Test: calibration and undistortion '''\n",
    "# Calibration\n",
    "ret, mtx, dist, rvecs, tvecs = calibration(\"camera_cal/*.jpg\", 9, 6)\n",
    "\n",
    "# Undistortion\n",
    "for img in os.listdir(\"camera_cal/\"):\n",
    "    img_cli = mpimg.imread(\"camera_cal/\"+img)\n",
    "    undistort = cv2.undistort(img_cli, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Visualize\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img_cli)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(undistort)\n",
    "    ax2.set_title('Undistorted Image', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' 5 Perspective Transform '''\n",
    "# Capture source corners from houghline \n",
    "def corners_from_houghlines(lines, y_min, y_max):\n",
    "    i = yr_mid = xr_mid = s_r = b_r = 0      # y_mid and x_mid: midpoint of houghline\n",
    "    j = yl_mid = xl_mid = s_l = b_l = 0      # s and b: slope and intercept of houghline\n",
    "       \n",
    "    # Seperate left and right lines\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:             \n",
    "            \n",
    "            # Right Lane Section\n",
    "            if 2>((x2-x1)/(y2-y1))>0: \n",
    "                i += 1\n",
    "                yr_mid += (y2 + y1)/2        # accumulate the midpoint y              \n",
    "                xr_mid += (x2 + x1)/2        # accumulate the midpoint x\n",
    "                s_r += (x2-x1) / (y2-y1)     # accumulate the slope\n",
    "                b_i = ((x2+x1) - (x2-x1)/(y2-y1)*(y2+y1))/ 2 \n",
    "                if i == 1:                   # accumulate the intercept b\n",
    "                    b_r = b_i\n",
    "                else:\n",
    "                    if abs(b_i - b_r/(i-1)) < 20: \n",
    "                        b_r = xr_mid - s_r/i * yr_mid\n",
    "                    else:                    # throw away deviated lines  \n",
    "                        i -= 1\n",
    "                        yr_mid -= (y2 + y1)/2\n",
    "                        xr_mid -= (x2 + x1)/2\n",
    "                        s_r -= (x2-x1) / (y2-y1)    \n",
    "            \n",
    "            # Left Lane Section\n",
    "            elif 0>((x2-x1)/(y2-y1))>-2: \n",
    "                j += 1\n",
    "                yl_mid += (y2 + y1)/2\n",
    "                xl_mid += (x2 + x1)/2\n",
    "                s_l += (x2-x1) / (y2-y1)\n",
    "                b_j = ((x2+x1) - (x2-x1)/(y2-y1)*(y2+y1))/ 2 \n",
    "                if j == 1:\n",
    "                    b_l = b_j\n",
    "                else:                    \n",
    "                    if abs(b_j - b_l/(j-1)) < 20:\n",
    "                        b_l = xl_mid - s_l/j * yl_mid\n",
    "                    else:                        \n",
    "                        j -= 1\n",
    "                        yl_mid -= (y2 + y1)/2\n",
    "                        xl_mid -= (x2 + x1)/2\n",
    "                        s_l -= (x2-x1) / (y2-y1)\n",
    "    \n",
    "    # Calculate lane corners [left_top, left_bottom, right_bottom, right_top]\n",
    "    if j == 0:\n",
    "        xl_top = xl_bottom = 0\n",
    "        print(\"Error: Left lane not found.\")\n",
    "    else:\n",
    "        xl_top = (s_l * y_min + b_l)/j\n",
    "        xl_bottom = (s_l * y_max + b_l)/j\n",
    "    \n",
    "    if i == 0:\n",
    "        xr_top = xr_bottom = 0\n",
    "        print(\"Error: Right lane not found.\")\n",
    "    else:\n",
    "        xr_top = (s_r * y_min + b_r)/i\n",
    "        xr_bottom = (s_r * y_max + b_r)/i  \n",
    "    \n",
    "    corners = np.float32([[xl_top, y_min], [xl_bottom, y_max], \n",
    "                          [xr_bottom, y_max], [xr_top, y_min]])\n",
    "    \n",
    "    return corners     \n",
    "\n",
    "\n",
    "# Input expecting combined_binary image (color channel=1)\n",
    "def perspective_transform(img, test=\"off\"): \n",
    "    # Mask image in black, except the triangle area where lane stays\n",
    "    mask = np.zeros_like(img)   \n",
    "    vertices = np.array([[(0,img.shape[0]),(img.shape[1]/2,img.shape[0]*.59),\n",
    "                          (img.shape[1],img.shape[0])]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    masked_img = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    # Generate the houghlines\n",
    "    rho = 1\n",
    "    theta = np.pi/360\n",
    "    threshold = 25\n",
    "    min_line_len = 1\n",
    "    max_line_gap = 100\n",
    "    \n",
    "    hough_line = cv2.HoughLinesP(masked_img, rho, theta, threshold, np.array([]),\n",
    "                                minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    #\n",
    "    for x1,y1,x2,y2 in hough_line[0]:\n",
    "        cv2.line(masked_img,(x1,y1), (x2,y2), (0,255,0),2)\n",
    "    #plt.imshow(masked_img)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # Capture source corners from houghline \n",
    "    corners = corners_from_houghlines(hough_line, y_min=img.shape[0]*0.625, \n",
    "                                     y_max=img.shape[0]*0.95)   \n",
    "    # Perspective transform\n",
    "    destinated = np.float32([[300,10],[300,700],[1100,700],[1100,10]]) # manual  \n",
    "    M = cv2.getPerspectiveTransform(corners, destinated)\n",
    "    Minv = cv2.getPerspectiveTransform(destinated, corners)\n",
    "    \n",
    "    \n",
    "    #-----UPDATING: Visualization for testing\n",
    "    if test == 'off':\n",
    "        return M, Minv\n",
    "    \n",
    "    if test == 'on':\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        binary_warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        # draw lines on combined_binary\n",
    "        img_out = np.dstack((img,img,img))*255\n",
    "        cv2.polylines(img_out, np.int32([corners]), True, (255,0,0), 5)\n",
    "        # draw lines on binary_warped\n",
    "        warped_out = np.dstack((binary_warped,binary_warped,binary_warped))*255\n",
    "        cv2.polylines(warped_out, np.int32([destinated]), True, (255,0,0), 5)\n",
    "        \n",
    "        return img_out, warped_out\n",
    "\n",
    "# cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "# (M calculated once as assuming the road is flat and the camera perspective hasn't changed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Function 4 & 5 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' - Test: image thresholding and perspective transform '''\n",
    "\n",
    "sx_thresh = (20,120) # x gradient\n",
    "sc_thresh = (170,255) # color\n",
    "\n",
    "for img in os.listdir(\"test_images/\"):\n",
    "    image_origin = mpimg.imread(\"test_images/\"+img)\n",
    "    image = np.copy(image_origin)\n",
    "        \n",
    "    undistort = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    combined_binary = color_gradient_threshold(undistort, sx_thresh, sc_thresh)\n",
    "    combined_binary_size = (combined_binary.shape[1], combined_binary.shape[0])\n",
    "    \n",
    "    c_b_wLine, warped_wLine = perspective_transform(combined_binary, test='on')\n",
    "    \n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(20,10))\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(undistort)\n",
    "    ax2.set_title('Undistorted Image', fontsize=20)\n",
    "    ax3.imshow(c_b_wLine, cmap='gray')\n",
    "    ax3.set_title('Threshold & Line', fontsize=20)\n",
    "    ax4.imshow(warped_wLine)\n",
    "    ax4.set_title('Warped & Line', fontsize=20)\n",
    "    #cv2.imwrite(\"output_images/\"+img, undistort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' 6 Polynomial fit lane line '''\n",
    "\n",
    "# Input expecting binary_warped image (color channel=1)\n",
    "def line_fit(img, test='off'):\n",
    "    # Restore the (y,x) of white color pixels\n",
    "    nonzeroy = np.array(img.nonzero()[0])\n",
    "    nonzerox = np.array(img.nonzero()[1]) \n",
    "\n",
    "    # Indices of pixels  \n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Parameters\n",
    "    margin = 100\n",
    "    minpix = 50\n",
    "    # Prepare an image to draw the lines\n",
    "    out_img = np.dstack((img,img,img))*255\n",
    "    \n",
    "    # Capture the lane line indices\n",
    "    if left.fit==[] or right.fit==[]: \n",
    "        # Find the lanes' starting point:\n",
    "        histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[0:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        # Slide the image \n",
    "        nwindows = 9\n",
    "        window_height = np.int(img.shape[0] / nwindows)\n",
    "        # x value of lane in each slide window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base        \n",
    "        \n",
    "        for window in range(nwindows):\n",
    "            # Rectangle vertices\n",
    "            win_y_low = img.shape[0] - (window+1) * window_height\n",
    "            win_y_high = img.shape[0] - window * window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            if test == 'on':\n",
    "                cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0,255,0), 2)\n",
    "                cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0,255,0), 2) \n",
    "                 \n",
    "            # Capture the lane pixels in the rectangle       \n",
    "            good_left_inds = ((nonzeroy>=win_y_low)&(nonzeroy<win_y_high) & \n",
    "                              (nonzerox>=win_xleft_low)&(nonzerox<win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy>=win_y_low)&(nonzeroy<win_y_high) &\n",
    "                               (nonzerox>=win_xright_low)&(nonzerox<win_xright_high)).nonzero()[0]\n",
    "\n",
    "            left_lane_inds.append(good_left_inds)         \n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            \n",
    "            if len(good_left_inds) > minpix: # update x value of lane for next slide window\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:\n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "       \n",
    "    # Capture the lane indices of continuous images\n",
    "    else:\n",
    "        # Capture the white pixels close to last image's lane\n",
    "        left_lane_inds = (\n",
    "            (nonzerox >= (left.fit[0]*nonzeroy**2 + left.fit[1]*nonzeroy + left.fit[2] - margin))\n",
    "            & (nonzerox < (left.fit[0]*nonzeroy**2 + left.fit[1]*nonzeroy + left.fit[2] + margin)))\n",
    "        right_lane_inds = (\n",
    "            (nonzerox >= (right.fit[0]*nonzeroy**2 + right.fit[1]*nonzeroy + right.fit[2] - margin))\n",
    "            & (nonzerox < (right.fit[0]*nonzeroy**2 + right.fit[1]*nonzeroy + right.fit[2] + margin)))\n",
    "    \n",
    "    # Capture the (y,x) of pixels which are lanes\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Polynomial fit\n",
    "    left.fit = np.polyfit(lefty, leftx, 2)\n",
    "    right.fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left.fitx = left.fit[0]*ploty**2 + left.fit[1]*ploty + left.fit[2]\n",
    "    right.fitx = right.fit[0]*ploty**2 + right.fit[1]*ploty + right.fit[2]\n",
    "    \n",
    "    # Calculate the curvature radius\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = (1 + (2* left.fit[0]*y_eval + left.fit[1])**2\n",
    "                    )**1.5 / np.absolute(2 * left.fit[0])\n",
    "    right_curverad = (1 + (2* right.fit[0]*y_eval + right.fit[1])**2\n",
    "                     )**1.5 / np.absolute(2 * right.fit[0])\n",
    "    lane_width = (left.fit[0]*y_eval**2 + left.fit[1]*y_eval + left.fit[2]) \n",
    "    - (right.fit[0]*y_eval**2 + right.fit[1]*y_eval + right.fit[2])\n",
    "    \n",
    "    # Convert from pixel to meters\n",
    "    ym_per_pix = 30 / img.shape[0]\n",
    "    xm_per_pix = 3.7 / lane_width     \n",
    "    l_fit_m = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    r_fit_m = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    left.curverad_m = (1 + (2*l_fit_m[0]*y_eval + l_fit_m[1])**2\n",
    "                    )**1.5 / np.absolute(2 * l_fit_m[0])\n",
    "    right.curverad_m = (1 + (2*r_fit_m[0]*y_eval + r_fit_m[1])**2\n",
    "                    )**1.5 / np.absolute(2 * r_fit_m[0])\n",
    "        \n",
    "    y_eval_m = y_eval * ym_per_pix\n",
    "    x_left_m = l_fit_m[0]*y_eval_m**2 + l_fit_m[1]*y_eval_m + l_fit_m[2]\n",
    "    x_right_m = r_fit_m[0]*y_eval_m**2 + r_fit_m[1]*y_eval_m + r_fit_m[2]\n",
    "    lane_width_m = x_left_m - x_right_m\n",
    "    \n",
    "    # Visualization for testing\n",
    "    if test == 'off':\n",
    "        return lane_width_m \n",
    "\n",
    "    if test == 'on':  \n",
    "        # Result1: Lane parameters in meters\n",
    "        print(\"Left & right curvature radius: %s m, %s m.\"%(left.curverad_m, right.curverad_m))\n",
    "        print(\"Left & right lane distance:\", lane_width_m)\n",
    "    \n",
    "        \n",
    "        # Highlight the lane pixels        \n",
    "        out_img[lefty, leftx] = [255,0,0]\n",
    "        out_img[righty, rightx] = [0,0,255] \n",
    "        \n",
    "        # Fill the lane line area\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        \n",
    "        left_lane_bound1 = np.array([np.transpose(np.vstack((left.fitx-margin, ploty)))])\n",
    "        left_lane_bound2 = np.array([np.flipud(np.transpose(np.vstack((left.fitx+margin, ploty))))])\n",
    "        left_lane_bound = np.hstack((left_lane_bound1, left_lane_bound2))\n",
    "    \n",
    "        right_lane_bound1 = np.array([np.transpose(np.vstack((right.fitx-margin, ploty)))])\n",
    "        right_lane_bound2 = np.array([np.flipud(np.transpose(np.vstack((right.fitx+margin, ploty))))])\n",
    "        right_lane_bound = np.hstack((right_lane_bound1, right_lane_bound2))\n",
    "\n",
    "        cv2.fillPoly(window_img, np.int_([left_lane_bound]), (0,255,0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_lane_bound]), (0,255,0))\n",
    "    \n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        \n",
    "        # Result2: Plot the image and the line\n",
    "        #plt.imshow(result)\n",
    "        #plt.plot(left_fitx, ploty, color='yellow')\n",
    "        #plt.plot(right_fitx, ploty, color='yellow')\n",
    "        \n",
    "        return result      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Function 6 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' - Test: polynomial fit lane line '''\n",
    "\n",
    "sx_thresh = (20,120) # x gradient\n",
    "sc_thresh = (170,255) # color\n",
    "\n",
    "for img in os.listdir(\"test_images/\"):\n",
    "    image_origin = mpimg.imread(\"test_images/\"+img)\n",
    "    image = np.copy(image_origin)\n",
    "        \n",
    "    undistort = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    combined_binary = color_gradient_threshold(undistort, sx_thresh, sc_thresh)\n",
    "    combined_binary_size = (combined_binary.shape[1], combined_binary.shape[0])\n",
    "    \n",
    "    M, Minv = perspective_transform(combined_binary)\n",
    "    binary_warped = cv2.warpPerspective(\n",
    "        combined_binary, M, combined_binary_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    left = Line()\n",
    "    right = Line()\n",
    "    warped_wLine = line_fit(binary_warped, test='on')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(20,10))\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(undistort)\n",
    "    ax2.set_title('Undistorted Image', fontsize=20)\n",
    "    ax3.imshow(binary_warped, cmap='gray')\n",
    "    ax3.set_title('Threshold', fontsize=20)\n",
    "    ax4.imshow(warped_wLine)\n",
    "    ax4.set_title('Warped & Line', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' 7 Lane area graphing '''\n",
    "# Expecting what image??? --binary_warped (why???)\n",
    "# -------params.Minv convert the warped image to combined_binary. Not sure what's the impact.\n",
    "def lane_zone_visualize(img):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    pts_left = np.array([np.transpose(np.vstack([left.fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right.fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, params.Minv, (img.shape[1], img.shape[0])) \n",
    "    \n",
    "    return newwarp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Function 7 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' - Test: polynomial fit lane line '''\n",
    "\n",
    "sx_thresh = (20,120) # x gradient\n",
    "sc_thresh = (170,255) # color\n",
    "\n",
    "for img in os.listdir(\"test_images/\"):\n",
    "    image_origin = mpimg.imread(\"test_images/\"+img)\n",
    "    image = np.copy(image_origin)\n",
    "        \n",
    "    undistort = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    combined_binary = color_gradient_threshold(undistort, sx_thresh, sc_thresh)\n",
    "    combined_binary_size = (combined_binary.shape[1], combined_binary.shape[0])\n",
    "    \n",
    "    params = Image_Parameters()\n",
    "    params.M, params.Minv = perspective_transform(combined_binary)\n",
    "    binary_warped = cv2.warpPerspective(\n",
    "        combined_binary, params.M, combined_binary_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    left = Line()\n",
    "    right = Line()\n",
    "    warped_wLine1 = line_fit(binary_warped, test='on')\n",
    "    warped_wLine = lane_zone_visualize(binary_warped)\n",
    "    result = cv2.addWeighted(undistort, 1, warped_wLine, 0.3, 0)\n",
    "    \n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "    ax1.imshow(undistort)\n",
    "    ax1.set_title('Undistorted Image', fontsize=20)\n",
    "    #ax2.imshow(combined_binary, cmap='gray')\n",
    "    #ax2.set_title('Threshold Image', fontsize=20)\n",
    "    #ax3.imshow(warped_wLine1, cmap='gray')\n",
    "    #ax3.set_title('Perspective Transform', fontsize=20)\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Undistorted & Line', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "These class objects should be defined \n",
    "before calling pipeline:\n",
    "    left = Line()\n",
    "    right = Line()\n",
    "    params = Line_Parameters()\n",
    "\n",
    "'''\n",
    "def pipeline(img, test='off'):\n",
    "    # Parameters\n",
    "    #img_size = (image.shape[1], image.shape[0])\n",
    "    sx_thresh = (20,120) # x gradient\n",
    "    sc_thresh = (170,255) # color\n",
    "    \n",
    "    # Undistortion\n",
    "    if params.calibrated == None:\n",
    "        params.calibrated = calibration(\"camera_cal/*.jpg\", 9, 6)\n",
    "    ret, mtx, dist, rvecs, tvecs = params.calibrated  \n",
    "    undistort = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Gradient & color threshold\n",
    "    combined_binary = color_gradient_threshold(undistort, sx_thresh, sc_thresh)\n",
    "    combined_binary_size = combined_binary.shape[1],combined_binary.shape[0]\n",
    "    \n",
    "    # Perspective transform\n",
    "    if params.M==[] or params.Minv==[]:\n",
    "        params.M, params.Minv = perspective_transform(combined_binary)\n",
    "    binary_warped = cv2.warpPerspective(\n",
    "        combined_binary, params.M, combined_binary_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Lane line fit\n",
    "    lane_width_m = line_fit(binary_warped)\n",
    "    \n",
    "    # Lane zone graphing\n",
    "    warped_wLine = lane_zone_visualize(binary_warped)\n",
    "      \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistort, 1, warped_wLine, 0.3, 0)\n",
    "    \n",
    "    if test == 'off':\n",
    "        return result\n",
    "    else: \n",
    "        # Visualize       \n",
    "        f, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original Image', fontsize=20)\n",
    "        ax2.imshow(result, cmap='gray')\n",
    "        ax2.set_title('Result Image', fontsize=20)\n",
    " \n",
    "        return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Test on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/project_video.mp4\n",
      "[MoviePy] Writing video output_images/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [04:25<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/project_video.mp4 \n",
      "\n",
      "CPU times: user 3min 43s, sys: 53.9 s, total: 4min 37s\n",
      "Wall time: 4min 27s\n",
      "The left lines's fit\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Define the class objects\n",
    "left = Line()\n",
    "right = Line()\n",
    "params = Image_Parameters()\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")#.subclip(0,5)\n",
    "clip_result = clip1.fl_image(pipeline)\n",
    "\n",
    "clip_save_addr = \"output_images/project_video.mp4\"\n",
    "%time clip_result.write_videofile(clip_save_addr, audio=False)\n",
    "\n",
    "print(\"The left lines's fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Right lane not found.\n",
      "[MoviePy] >>>> Building video output_images/challenge_video.mp4\n",
      "[MoviePy] Writing video output_images/challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [01:17<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/challenge_video.mp4 \n",
      "\n",
      "CPU times: user 1min 15s, sys: 12.9 s, total: 1min 27s\n",
      "Wall time: 1min 19s\n",
      "The left lines's fit\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Define the class objects\n",
    "left = Line()\n",
    "right = Line()\n",
    "params = Image_Parameters()\n",
    "\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")#.subclip(0,5)\n",
    "clip_result = clip1.fl_image(pipeline)\n",
    "\n",
    "clip_save_addr = \"output_images/challenge_video.mp4\"\n",
    "%time clip_result.write_videofile(clip_save_addr, audio=False)\n",
    "\n",
    "print(\"The left lines's fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/harder_challenge_video.mp4\n",
      "[MoviePy] Writing video output_images/harder_challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1003/1200 [02:36<00:24,  7.91it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-172>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-171>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    347\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                            progress_bar=progress_bar)\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     for t,frame in clip.iter_frames(progress_bar=progress_bar, with_times=True,\n\u001b[0;32m--> 209\u001b[0;31m                                     fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0;31m# Update and print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-136>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f05be9c6d14f>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(img, test)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Lane line fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mlane_width_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Lane zone graphing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1040962cb183>\u001b[0m in \u001b[0;36mline_fit\u001b[0;34m(img, test)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Polynomial fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WoooodyAmadeus/anaconda/envs/carnd-term1/lib/python3.5/site-packages/numpy/lib/polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 1D vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected non-empty vector for x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The left lines's fit\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Define the class objects\n",
    "left = Line()\n",
    "right = Line()\n",
    "params = Image_Parameters()\n",
    "\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")#.subclip(0,5)\n",
    "clip_result = clip1.fl_image(pipeline)\n",
    "\n",
    "clip_save_addr = \"output_images/harder_challenge_video.mp4\"\n",
    "%time clip_result.write_videofile(clip_save_addr, audio=False)\n",
    "\n",
    "print(\"The left lines's fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Pipeline test on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' - Test: Pipeline '''\n",
    "# Define the class objects\n",
    "left = Line()\n",
    "right = Line()\n",
    "params = Image_Parameters()\n",
    "\n",
    "for img in os.listdir(\"test_images/\"):\n",
    "    image_origin = mpimg.imread(\"test_images/\"+img)\n",
    "    image = np.copy(image_origin)\n",
    "    result = pipeline(image, test='on')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
